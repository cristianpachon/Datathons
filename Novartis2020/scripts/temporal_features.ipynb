{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "full_raw_initial_dataset_path = os.path.join(data_dir, 'gx_merged_lags_months.csv')\n",
    "volume_path = os.path.join(data_dir, 'gx_volume.csv')\n",
    "train_path = os.path.join(data_dir, 'train_split.csv')\n",
    "features_path = os.path.join(data_dir, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = pd.read_csv(volume_path, index_col=0)\n",
    "train_ids = pd.read_csv(train_path)\n",
    "full_raw_initial_dataset = pd.read_csv(full_raw_initial_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_initial_dataset = full_raw_initial_dataset.loc[\n",
    "    full_raw_initial_dataset.test == 0,:].drop(columns = 'test').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_initial_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_volume(country, brand, month_num, length_serie, func):\n",
    "    ind = (volume.country == country) & (volume.brand == brand) & (volume.month_num <month_num)\n",
    "    volume_filter = volume.loc[ind, :]\n",
    "    volume_sorted = volume_filter.sort_values(by=['month_num'], ascending=False)\n",
    "    volume_sorted.reset_index(inplace=True, drop=True)\n",
    "    total_obs = len(volume_sorted)\n",
    "    total_to_select = length_serie if length_serie<=total_obs else total_obs \n",
    "    volumes_selected = volume_sorted.volume[:total_to_select].values\n",
    "    return func(volumes_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create initial datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_ids.merge(\n",
    "    full_initial_dataset,\n",
    "    'inner',\n",
    "    on=['country', 'brand']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanitiy checks\n",
    "assert len(train.loc[:,['country', 'brand', 'month_num']].drop_duplicates()) == \\\n",
    "len(train), 'duplicated'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add feature\n",
    "$$vol_{-1}$$\n",
    "* Name: volume_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_at_1 = volume.loc[volume.month_num == -1, ['country', 'brand', 'volume']].\\\n",
    "            drop_duplicates().\\\n",
    "            rename(columns={'volume':'volume_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_with_volume_1 = full_initial_dataset.merge(\n",
    "    volume_at_1,\n",
    "    'left',\n",
    "    on=['country', 'brand']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(full_initial_dataset) == len(full_with_volume_1), 'There are duplicated'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add feature\n",
    "$$log\\Big(\\frac{vol_{t} + 1}{vol_{-1}}\\Big)$$\n",
    "* Name: log_relative_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_relative_volume = train.merge(\n",
    "    volume_at_1,\n",
    "    'left',\n",
    "    on=['country', 'brand']\n",
    ")\n",
    "train_with_relative_volume['log_relative_volume'] = np.log(\n",
    "    (train_with_relative_volume.volume+1)/(train_with_relative_volume.volume_1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_relative_volume.sort_values(by=['country', 'brand', 'month_num'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_relative_volume['lag_log_relative_volume'] = train_with_relative_volume.groupby(\n",
    "    ['country', 'brand'])['log_relative_volume'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_relative_volume['lag_log_relative_volume'] = np.where(\n",
    "    train_with_relative_volume.month_num == 0,\n",
    "    np.log((1+train_with_relative_volume.volume_1)/train_with_relative_volume.volume_1),\n",
    "    train_with_relative_volume.lag_log_relative_volume\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_with_relative_volume.drop(columns=['volume', 'log_relative_volume'])\n",
    "target = train_with_relative_volume['log_relative_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['country', 'brand', 'therapeutic_area', 'presentation', 'month_name']\n",
    "te = TargetEncoder(cols=categorical_cols)\n",
    "pipe  = Pipeline([\n",
    "    (\"te\", te),\n",
    "    (\"imp\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"sc\", StandardScaler()),\n",
    "    (\"model\", Lasso(alpha=0.001, max_iter=2000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe[-1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_relative_volume(model, features):\n",
    "    features_copy = features.copy()\n",
    "    features_copy.sort_values(by=['country', 'brand', 'month_num'], inplace=True)\n",
    "    features_copy['log_relative_volume'] = float('-inf')\n",
    "    i=0\n",
    "    for index, row in features_copy.iterrows():\n",
    "        if(i%5000 == 0):\n",
    "            print('Iteration:', i)\n",
    "        \n",
    "        country = row.country\n",
    "        brand = row.brand\n",
    "        month = row.month_num\n",
    "        \n",
    "        if month==0:\n",
    "            row.at['lag_log_relative_volume'] = 0\n",
    "        else:\n",
    "            ind = (features_copy.brand == brand) &\\\n",
    "            (features_copy.country == country) &\\\n",
    "            (features_copy.month_num == month-1) \n",
    "            lag_log_relative_volume = features_copy.loc[ind, 'log_relative_volume']\n",
    "            row.at['lag_log_relative_volume'] = lag_log_relative_volume\n",
    "        \n",
    "        df = row.to_frame().T.drop(columns=['log_relative_volume'])\n",
    "        pred_val = model.predict(df)\n",
    "        ind = (features_copy.brand == brand) & (features_copy.country == country) & (features_copy.month_num == month) \n",
    "        features_copy.loc[ind, 'log_relative_volume'] = pred_val[0]\n",
    "        i+=1\n",
    "    return features_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = get_log_relative_volume(\n",
    "    pipe, \n",
    "    full_with_volume_1.loc[:, features.columns[:-1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(preds) == len(full_with_volume_1), 'Duplicated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(preds['log_relative_volume'].isna()) == 0, 'Missing'\n",
    "assert sum(preds['log_relative_volume'].isnull()) == 0, 'Missing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = preds.loc[\n",
    "    :, \n",
    "    ['country', 'brand', 'month_num', 'volume_1', 'log_relative_volume']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(features_df) == len(features_df.loc[:, ['country', 'brand', 'month_num']]), 'Duplicates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv(os.path.join(features_path, 'feat_01.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add feature\n",
    "$$log\\Big(\\frac{vol_{t} + 1}{vol_{t-1}+1}\\Big)$$\n",
    "\n",
    "* Name: relative_volume_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_predicted_log_relative_volume = train.merge(\n",
    "    preds.loc[:, ['country', 'brand', 'month_num', 'volume_1', 'log_relative_volume']],\n",
    "    'inner',\n",
    "    on=['country', 'brand', 'month_num']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_with_predicted_log_relative_volume) == len(train), 'Duplicated values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_previous_month = train_with_predicted_log_relative_volume.copy()\n",
    "volume_previous_month['previous_month'] = volume_previous_month.month_num - 1\n",
    "volume_previous_month = volume_previous_month.merge(\n",
    "    volume.loc[: , ['country', 'brand', 'volume', 'month_num']].rename(\n",
    "        columns={'volume':'volume_lag_1', 'month_num':'previous_month'}\n",
    "    ),\n",
    "    'left',\n",
    "    on=['country', 'brand', 'previous_month']\n",
    ").merge(\n",
    "    volume.loc[volume.month_num == -2, ['country', 'brand', 'volume']].rename(\n",
    "        columns={'volume':'volume_2'}\n",
    "    ),\n",
    "    'left',\n",
    "    on=['country', 'brand']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(volume_previous_month) == len(train_with_predicted_log_relative_volume), 'Duplicated values'\n",
    "assert sum(volume_previous_month.volume_lag_1.isna()) == 0, 'NA values'\n",
    "assert sum(volume_previous_month.volume_lag_1.isnull()) == 0, 'NA values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(volume_previous_month.volume_2.isna()) == 0, 'NA values'\n",
    "assert sum(volume_previous_month.volume_2.isnull()) == 0, 'NA values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_previous_month['log_relative_volume_previous'] = np.log(\n",
    "    (volume_previous_month.volume + 1)/(volume_previous_month.volume_lag_1 + 1)\n",
    ")\n",
    "volume_previous_month['log_relative_volume_1'] = np.log(\n",
    "    (volume_previous_month.volume_1 + 1)/(volume_previous_month.volume_2 + 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(volume_previous_month.log_relative_volume_previous.isna()) == 0, 'log_relative_volume_previous contains NA values'\n",
    "assert sum(volume_previous_month.log_relative_volume_previous.isnull()) == 0, 'log_relative_volume_previous contains null values'\n",
    "assert sum(volume_previous_month.log_relative_volume_previous == np.inf) == 0, 'log_relative_volume_previous contains inf values'\n",
    "assert sum(volume_previous_month.log_relative_volume_previous == -np.inf) == 0, 'log_relative_volume_previous contains -inf values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(volume_previous_month.log_relative_volume_1.isna()) == 0, 'relative_volume_1 contains NA values'\n",
    "assert sum(volume_previous_month.log_relative_volume_1.isnull()) == 0, 'relative_volume_1 contains null values'\n",
    "assert sum(volume_previous_month.log_relative_volume_1 == np.inf) == 0, 'relative_volume_1 contains inf values'\n",
    "assert sum(volume_previous_month.log_relative_volume_1 == -np.inf) == 0, 'relative_volume_1 contains -inf values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_previous_month['lag_log_relative_volume_previous'] = volume_previous_month.groupby(\n",
    "    ['country', 'brand'])['log_relative_volume_previous'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_previous_month['lag_log_relative_volume_previous'] = np.where(\n",
    "    volume_previous_month.month_num == 0,\n",
    "    volume_previous_month.log_relative_volume_1,\n",
    "    volume_previous_month.lag_log_relative_volume_previous\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_previous_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(preds.columns) + ['lag_log_relative_volume_previous'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = volume_previous_month.loc[:, cols]\n",
    "target = volume_previous_month.log_relative_volume_previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['country', 'brand', 'therapeutic_area', 'presentation', 'month_name']\n",
    "te = TargetEncoder(cols=categorical_cols)\n",
    "pipe2  = Pipeline([\n",
    "    (\"te\", te),\n",
    "    (\"imp\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"sc\", StandardScaler()),\n",
    "    (\"model\", Lasso(alpha=0.001, max_iter=2000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_relative_volume_previous(model, features):\n",
    "    features_copy = features.copy()\n",
    "    features_copy.sort_values(by=['country', 'brand', 'month_num'], inplace=True)\n",
    "    features_copy['log_relative_volume_previous'] = float('-inf')\n",
    "    i=0\n",
    "    \n",
    "    for index, row in features_copy.iterrows():\n",
    "        if(i%5000 == 0):\n",
    "            print('Iteration:', i)\n",
    "        country = row.country\n",
    "        brand = row.brand\n",
    "        month = row.month_num\n",
    "        \n",
    "        if month == 0:\n",
    "            volume_1 = find_closest_volume(country, brand, 0, 1, np.mean)\n",
    "            volume_2 = find_closest_volume(country, brand, -1, 1, np.mean)\n",
    "            lag_log_relative_volume_previous = np.log((volume_1 + 1)/(volume_2+1))\n",
    "        else:\n",
    "            ind = (features_copy.country == country) &\\\n",
    "            (features_copy.brand == brand) &\\\n",
    "            (features_copy.month_num == month -1)\n",
    "            lag_log_relative_volume_previous = features_copy.loc[ind, 'log_relative_volume_previous']\n",
    "\n",
    "        row.at['lag_log_relative_volume_previous'] = lag_log_relative_volume_previous\n",
    "        df = row.to_frame().T.drop(columns=['log_relative_volume_previous'])\n",
    "        pred_val = model.predict(df)\n",
    "        ind = (features_copy.brand == brand) & (features_copy.country == country) & (features_copy.month_num == month) \n",
    "        features_copy.loc[ind, 'log_relative_volume_previous'] = pred_val[0]\n",
    "        i+=1\n",
    "    return features_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = get_log_relative_volume_previous(pipe2, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = preds2.loc[\n",
    "    :, \n",
    "    ['country', 'brand', 'month_num', 'volume_1', 'log_relative_volume', 'log_relative_volume_previous']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv(os.path.join(features_path, 'feat_02.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
