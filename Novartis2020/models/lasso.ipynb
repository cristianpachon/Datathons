{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from tools.metrics import (\n",
    "    apply_metrics,\n",
    "    prep_data_for_metric,\n",
    "    get_avg_volumes,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(preds, lower, upper, y, X, avg_volumes):\n",
    "\n",
    "    id_cols = [\"country\", \"brand\"]\n",
    "\n",
    "    prepped_X = prep_data_for_metric(X, avg_volumes)\n",
    "\n",
    "    prepped_X[\"actuals\"] = y\n",
    "    prepped_X[\"forecast\"] = preds\n",
    "    prepped_X[\"lower_bound\"] = lower\n",
    "    prepped_X[\"upper_bound\"] = upper\n",
    "\n",
    "    return np.mean(abs(prepped_X.groupby(id_cols).apply(apply_metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "train_path = os.path.join(data_dir, 'train_split.csv')\n",
    "valid_path = os.path.join(data_dir, 'valid_split.csv')\n",
    "features_path =  os.path.join(data_dir, 'features', 'feat_02.csv')\n",
    "full_dataset_path = os.path.join(data_dir, 'gx_merged_lags_months.csv')\n",
    "volume_path = os.path.join(data_dir, 'gx_volume.csv')\n",
    "submision_template_path = os.path.join(data_dir, 'submission_template.csv')\n",
    "submissions_folder = os.path.join(root_dir, 'submissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv(full_dataset_path)\n",
    "train = pd.read_csv(train_path)\n",
    "validation = pd.read_csv(valid_path)\n",
    "volume = pd.read_csv(volume_path, index_col=0)\n",
    "submision = pd.read_csv(submision_template_path)\n",
    "features = pd.read_csv(features_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_enriched = full.merge(\n",
    "    features,\n",
    "    'left',\n",
    "    on=['country', 'brand', 'month_num']\n",
    ")\n",
    "full_enriched['target'] = np.log((full_enriched.volume + 1)/(full_enriched.volume_1 +1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = full_enriched.loc[full_enriched.test == 1, :]\n",
    "train_eval = full_enriched.loc[full_enriched.test == 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.loc[(features.country == 'country_9') & (features.brand == 'brand_187')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_features = train.merge(train_eval, 'inner', on=['country', 'brand'])\n",
    "validation_with_features = validation.merge(train_eval, 'inner', on=['country', 'brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_drop = ['volume', 'target', 'test', 'log_relative_volume']\n",
    "to_drop = ['volume', 'target', 'test']\n",
    "categorical_cols = ['country', 'brand', 'therapeutic_area', 'presentation', 'month_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_with_features.drop(columns=to_drop)\n",
    "train_y = train_with_features.log_relative_volume\n",
    "val_x = validation_with_features.drop(columns=to_drop)\n",
    "val_y = validation_with_features.log_relative_volume\n",
    "test_x = test.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['country', 'brand', 'therapeutic_area', 'presentation', 'month_name']\n",
    "te = TargetEncoder(cols=categorical_cols)\n",
    "pipe  = Pipeline([\n",
    "    (\"te\", te),\n",
    "    (\"imp\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"sc\", StandardScaler()),\n",
    "    (\"model\", Lasso(alpha=0.001, max_iter=2000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['country', 'brand', 'therapeutic_area', 'presentation', 'month_name']\n",
    "te = TargetEncoder(cols=categorical_cols)\n",
    "pipe  = Pipeline([\n",
    "    (\"te\", te),\n",
    "    (\"model\", RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = pipe.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_with_features['prediction'] = val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_months = range(24)\n",
    "n_boots = 500\n",
    "error_estimate = {}\n",
    "for month in n_months:\n",
    "    i = 0\n",
    "    df_filter = validation_with_features[validation_with_features.month_num == month].reset_index()\n",
    "    list_error = []\n",
    "    while i < n_boots:\n",
    "        idx = np.random.choice(len(df_filter), len(df_filter))\n",
    "        boot_df = df_filter.iloc[idx, :]\n",
    "        error = np.abs((sum(boot_df.target) - sum(boot_df.prediction))/sum(boot_df.prediction))\n",
    "        list_error.append(error)\n",
    "        i += 1\n",
    "    error_estimate[month] = np.mean(list_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_with_features['predicted_volume'] = np.exp(validation_with_features.prediction) * validation_with_features.volume_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rate(month):\n",
    "    return error_estimate[month]\n",
    "validation_with_features['rate'] = validation_with_features.apply(lambda x: return_rate(x['month_num']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_with_features['upper'] = validation_with_features.predicted_volume*(1+validation_with_features.rate)\n",
    "validation_with_features['lower'] = validation_with_features.predicted_volume*(1-validation_with_features.rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_volumes = get_avg_volumes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_pair = compute_metrics(\n",
    "                    preds=validation_with_features.predicted_volume,\n",
    "                    lower=validation_with_features.lower,\n",
    "                    upper=validation_with_features.upper,\n",
    "                    y=validation_with_features.volume,\n",
    "                    X=val_x,\n",
    "                    avg_volumes=avg_volumes\n",
    "                )\n",
    "print(metric_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
