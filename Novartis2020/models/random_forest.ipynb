{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from tools.metrics import (\n",
    "    apply_metrics,\n",
    "    prep_data_for_metric,\n",
    "    get_avg_volumes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(preds, lower, upper, y, X, avg_volumes):\n",
    "\n",
    "    id_cols = [\"country\", \"brand\"]\n",
    "\n",
    "    prepped_X = prep_data_for_metric(X, avg_volumes)\n",
    "\n",
    "    prepped_X[\"actuals\"] = y\n",
    "    prepped_X[\"forecast\"] = preds\n",
    "    prepped_X[\"lower_bound\"] = lower\n",
    "    prepped_X[\"upper_bound\"] = upper\n",
    "\n",
    "    return np.mean(abs(prepped_X.groupby(id_cols).apply(apply_metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "train_path = os.path.join(data_dir, 'train_split.csv')\n",
    "valid_path = os.path.join(data_dir, 'valid_split.csv')\n",
    "full_dataset_path = os.path.join(data_dir, 'gx_merged_lags_months.csv')\n",
    "volume_path = os.path.join(data_dir, 'gx_volume.csv')\n",
    "submision_template_path = os.path.join(data_dir, 'submission_template.csv')\n",
    "submissions_folder = os.path.join(root_dir, submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv(full_dataset_path)\n",
    "train = pd.read_csv(train_path)\n",
    "validation = pd.read_csv(valid_path)\n",
    "volume = pd.read_csv(volume_path, index_col=0)\n",
    "submision = pd.read_csv(submision_template_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_at_1 = volume.loc[volume.month_num == -1, ['country', 'brand', 'volume']].\\\n",
    "            drop_duplicates().\\\n",
    "            rename(columns={'volume':'volume_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_enriched = full.merge(volume_at_1, 'left', on=['country', 'brand'])\n",
    "full_enriched['relative_volume'] = np.log((1 + full_enriched.volume)/full_enriched.volume_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_enriched.sort_values(by = ['test', 'country', 'brand', 'month_num'], inplace=True)\n",
    "full_enriched['lag_relative_volume'] = full_enriched.\\\n",
    "    groupby(['test', 'country', 'brand'])['relative_volume'].shift(1)\n",
    "full_enriched['lag_relative_volume'] = np.where(\n",
    "    full_enriched['month_num'] == 0, \n",
    "    0, \n",
    "    full_enriched['lag_relative_volume']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = full_enriched.loc[full_enriched.test == 1, :]\n",
    "train_eval = full_enriched.loc[full_enriched.test == 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_features = train.merge(train_eval, 'inner', on=['country', 'brand'])\n",
    "validation_with_features = validation.merge(train_eval, 'inner', on=['country', 'brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['volume', 'relative_volume']\n",
    "categorical_cols = ['country', 'brand', 'therapeutic_area', 'presentation', 'month_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_with_features.drop(columns=to_drop)\n",
    "train_y = train_with_features.relative_volume\n",
    "val_x = validation_with_features.drop(columns=to_drop)\n",
    "val_y = validation_with_features.relative_volume\n",
    "test_x = test.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TargetEncoder(cols=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_forest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "        ('te', te),\n",
    "        ('ran_forest', ran_forest)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = pipe.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_with_features['prediction'] = val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_months = range(24)\n",
    "n_boots = 500\n",
    "error_estimate = {}\n",
    "for month in n_months:\n",
    "    i = 0\n",
    "    df_filter = validation_with_features[validation_with_features.month_num == month].reset_index()\n",
    "    list_error = []\n",
    "    while i < n_boots:\n",
    "        idx = np.random.choice(len(df_filter), len(df_filter))\n",
    "        boot_df = df_filter.iloc[idx, :]\n",
    "        error = np.abs((sum(boot_df.relative_volume) - sum(boot_df.prediction))/sum(boot_df.prediction))\n",
    "        list_error.append(error)\n",
    "        i += 1\n",
    "    error_estimate[month] = np.mean(list_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_with_features['predicted_volume'] = np.exp(validation_with_features.prediction) * validation_with_features.volume_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rate(month):\n",
    "    return error_estimate[month]\n",
    "\n",
    "validation_with_features['rate'] = validation_with_features.apply(lambda x: return_rate(x['month_num']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_with_features['upper'] = validation_with_features.predicted_volume*(1+validation_with_features.rate)\n",
    "validation_with_features['lower'] = validation_with_features.predicted_volume*(1-validation_with_features.rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_volumes = get_avg_volumes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_pair = compute_metrics(\n",
    "                    preds=validation_with_features.predicted_volume,\n",
    "                    lower=validation_with_features.lower,\n",
    "                    upper=validation_with_features.upper,\n",
    "                    y=validation_with_features.volume,\n",
    "                    X=val_x,\n",
    "                    avg_volumes=avg_volumes\n",
    "                )\n",
    "print(metric_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.reset_index(inplace=True, drop=True)\n",
    "test_copy = test.copy()\n",
    "test_copy.sort_values(by=['country', 'brand', 'month_num'], inplace=True)\n",
    "test_copy['relative_volume'] = float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < len(test_copy):\n",
    "    row = test_copy.iloc[i, :]\n",
    "\n",
    "    country = row.country\n",
    "    brand = row.brand\n",
    "    month = row.month_num\n",
    "    \n",
    "    if row.month_num==0:\n",
    "        row.at['lag_relative_volume'] = 0\n",
    "    else:\n",
    "        ind = (test_copy.brand == brand) & (test_copy.country == country) & (test_copy.month_num == month-1) \n",
    "        lag_relative_volume = test_copy.loc[ind, 'relative_volume']\n",
    "        row.at['lag_relative_volume'] = lag_relative_volume\n",
    "    pred_val = pipe.predict(row.to_frame().T.drop(columns=['relative_volume', 'volume']))\n",
    "    ind = (test_copy.brand == brand) & (test_copy.country == country) & (test_copy.month_num == month) \n",
    "    test_copy.loc[ind, 'relative_volume'] = pred_val[0]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy['prediction'] = np.exp(test_copy.relative_volume)*test_copy.volume_1\n",
    "test_copy['rate'] = test_copy.apply(lambda x: return_rate(x['month_num']), axis=1)\n",
    "test_copy['pred_95_low'] = (1-test_copy.rate)*test_copy.prediction\n",
    "test_copy['pred_95_high'] = (1+test_copy.rate)*test_copy.prediction\n",
    "test_copy_selected_colums = test_copy.loc[:, ['country', 'brand', 'month_num', 'pred_95_low', 'prediction', 'pred_95_high']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy_selected_colums.to_csv(\n",
    "    os.path.join(submissions_folder, 'random_forest.csv'), \n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
